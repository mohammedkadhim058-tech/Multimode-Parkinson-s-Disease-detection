{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d470db5",
   "metadata": {},
   "source": [
    "# Fusion â€” Logistic Meta-Learner (Baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48dae7f",
   "metadata": {},
   "source": [
    "\n",
    "Combine calibrated probabilities from VoiceNet and GaitNet using a simple **logistic regression** trained on your validation folds.\n",
    "This notebook expects the CV prediction files produced by the other notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1e29c",
   "metadata": {},
   "source": [
    "## Install/verify dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b97836",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, subprocess, importlib\n",
    "\n",
    "def ensure(pkg, import_name=None):\n",
    "    try:\n",
    "        importlib.import_module(import_name or pkg)\n",
    "        print(f\"{import_name or pkg} OK\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "        importlib.import_module(import_name or pkg)\n",
    "        print(f\"{import_name or pkg} installed\")\n",
    "\n",
    "ensure(\"pandas\")\n",
    "ensure(\"numpy\")\n",
    "ensure(\"scikit-learn\", import_name=\"sklearn\")\n",
    "ensure(\"matplotlib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e42bda",
   "metadata": {},
   "source": [
    "## Load predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc5820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "MANIFESTS = Path(r\"C:\\Users\\muham\\_Projects\\PD New\\manifests\")\n",
    "MODELS = MANIFESTS / \"models\"\n",
    "\n",
    "v = pd.read_csv(MODELS/\"voicenet_cv_predictions.csv\")      # columns: path, subject_id, split2, y_true, p_voice\n",
    "# If you also export gait CV preds, load here (for now, we use gaitnet window CV probs via the GaitNet notebook)\n",
    "# We'll create a subject-level aggregate for gait: max prob per subject to reflect worst-case FOG.\n",
    "try:\n",
    "    g_meta = pd.read_csv(MANIFESTS/'gait_manifest_splits.csv')\n",
    "except Exception as e:\n",
    "    g_meta = None\n",
    "    print(\"Could not load gait manifest splits:\", e)\n",
    "\n",
    "# For simplicity, we set p_gait=NaN (not available) at subject level unless you aggregate and save it after training.\n",
    "# You can update this later to use a proper subject-level aggregation from GaitNet.\n",
    "sv = v.groupby(\"subject_id\", dropna=False)[\"p_voice\"].mean().reset_index().rename(columns={\"p_voice\":\"p_voice_mean\"})\n",
    "sv[\"y_true\"] = v.groupby(\"subject_id\", dropna=False)[\"y_true\"].max().values\n",
    "\n",
    "# placeholder p_gait if you have subject ids in gait metadata\n",
    "if g_meta is not None and \"subject_id\" in g_meta.columns:\n",
    "    g_subjects = g_meta[g_meta[\"split\"]==\"train\"].groupby(\"subject_id\").size().reset_index().rename(columns={0:\"n\"})\n",
    "    sv = sv.merge(g_subjects[[\"subject_id\"]], on=\"subject_id\", how=\"left\")\n",
    "else:\n",
    "    sv[\"subject_id\"] = sv[\"subject_id\"]\n",
    "\n",
    "sv[\"p_gait\"] = np.nan  # fill later when you export gait subject-level predictions\n",
    "print(sv.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb55640",
   "metadata": {},
   "source": [
    "## Train fusion model (handles missing p_gait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "X = sv[[\"p_voice\",\"p_voice_mean\"]].copy() if \"p_voice\" in sv.columns else sv[[\"p_voice_mean\"]].copy()\n",
    "# If gait probs available later, add: X[\"p_gait\"] = sv[\"p_gait\"]\n",
    "y = sv[\"y_true\"].astype(int).values\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "probs, trues = [], []\n",
    "for tr, te in kf.split(X):\n",
    "    pipe.fit(X.iloc[tr], y[tr])\n",
    "    p = pipe.predict_proba(X.iloc[te])[:,1]\n",
    "    probs.append(p); trues.append(y[te])\n",
    "probs = np.concatenate(probs); trues = np.concatenate(trues)\n",
    "\n",
    "print(\"Fusion CV AUC:\", roc_auc_score(trues, probs))\n",
    "print(\"Fusion CV ACC:\", accuracy_score(trues, probs>0.5))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
